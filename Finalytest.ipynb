{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE:loading_resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE:loading_finished\n"
     ]
    }
   ],
   "source": [
    "from detection.DataGenerator import train_based_self_detection\n",
    "from detection.Loader.ResNet50Loader import Resnet50Loader\n",
    "import detection.Spliter\n",
    "import torch\n",
    "from torch import nn\n",
    "print(\"CODE:loading_resnet50\")\n",
    "model=Resnet50Loader().load()\n",
    "print(\"CODE:loading_finished\")\n",
    "device='cuda:2'\n",
    "back_device='cuda:2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建量化模型用于测试acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization.observer import MovingAveragePerChannelMinMaxObserver\n",
    "observer = MovingAveragePerChannelMinMaxObserver(ch_axis=0).to(device)\n",
    "\n",
    "class quantiseze_model(nn.Module):\n",
    "    def __init__(self,model_list):\n",
    "        super(quantiseze_model,self).__init__()\n",
    "        self.model_list=model_list\n",
    "    def forward(self,x):\n",
    "        x=self.model_list[0](x)\n",
    "        observer(x)\n",
    "        scale, zero_point = observer.calculate_qparams()\n",
    "        # scale=scale.to(device)\n",
    "        # zero_point=zero_point.to(device)\n",
    "        x_quantized = torch.quantize_per_channel(x, scales=scale, zero_points=zero_point, axis=0, dtype=torch.qint8)\n",
    "        x=self.model_list[1](x_quantized.dequantize())\n",
    "        observer(x)\n",
    "        scale, zero_point = observer.calculate_qparams()\n",
    "        # scale=scale.to(device)\n",
    "        # zero_point=zero_point.to(device)\n",
    "        x_quantized = torch.quantize_per_channel(x, scales=scale, zero_points=zero_point, axis=0, dtype=torch.qint8)\n",
    "        x=self.model_list[2](x_quantized.dequantize())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.0\n",
      "loss: 8.444656372070312\n",
      "acc: 0.0\n",
      "loss: 8.303812980651855\n",
      "acc: 0.0\n",
      "loss: 8.1074800491333\n",
      "acc: 0.0\n",
      "loss: 7.924959659576416\n",
      "acc: 0.0\n",
      "loss: 7.753497123718262\n",
      "acc: 0.0\n",
      "loss: 7.591139793395996\n",
      "acc: 0.0\n",
      "loss: 7.436631679534912\n",
      "acc: 0.01\n",
      "loss: 7.287731170654297\n",
      "acc: 0.01\n",
      "loss: 7.143582820892334\n",
      "acc: 0.02\n",
      "loss: 7.003101825714111\n",
      "acc: 0.02\n",
      "loss: 6.865771293640137\n",
      "acc: 0.02\n",
      "loss: 6.729814529418945\n",
      "acc: 0.02\n",
      "loss: 6.595409393310547\n",
      "acc: 0.03\n",
      "loss: 6.462466716766357\n",
      "acc: 0.04\n",
      "loss: 6.329666614532471\n",
      "acc: 0.04\n",
      "loss: 6.196863651275635\n",
      "acc: 0.04\n",
      "loss: 6.064444065093994\n",
      "acc: 0.04\n",
      "loss: 5.9326171875\n",
      "acc: 0.04\n",
      "loss: 5.800970554351807\n",
      "acc: 0.05\n",
      "loss: 5.669297218322754\n",
      "acc: 0.08\n",
      "loss: 5.538058280944824\n",
      "acc: 0.1\n",
      "loss: 5.406550884246826\n",
      "acc: 0.1\n",
      "loss: 5.275132179260254\n",
      "acc: 0.13\n",
      "loss: 5.1435346603393555\n",
      "acc: 0.15\n",
      "loss: 5.011880874633789\n",
      "acc: 0.16\n",
      "loss: 4.880213737487793\n",
      "acc: 0.16\n",
      "loss: 4.748531818389893\n",
      "acc: 0.19\n",
      "loss: 4.6167826652526855\n",
      "acc: 0.21\n",
      "loss: 4.48527193069458\n",
      "acc: 0.21\n",
      "loss: 4.354934215545654\n",
      "acc: 0.23\n",
      "loss: 4.2257771492004395\n",
      "acc: 0.23\n",
      "loss: 4.097592830657959\n",
      "acc: 0.26\n",
      "loss: 3.9710142612457275\n",
      "acc: 0.27\n",
      "loss: 3.8453166484832764\n",
      "acc: 0.29\n",
      "loss: 3.7208142280578613\n",
      "acc: 0.33\n",
      "loss: 3.5978453159332275\n",
      "acc: 0.35\n",
      "loss: 3.476585626602173\n",
      "acc: 0.39\n",
      "loss: 3.3568811416625977\n",
      "acc: 0.41\n",
      "loss: 3.2389485836029053\n",
      "acc: 0.44\n",
      "loss: 3.122443199157715\n",
      "acc: 0.45\n",
      "loss: 3.007657289505005\n",
      "acc: 0.49\n",
      "loss: 2.8949217796325684\n",
      "acc: 0.5\n",
      "loss: 2.7839720249176025\n",
      "acc: 0.52\n",
      "loss: 2.674997568130493\n",
      "acc: 0.55\n",
      "loss: 2.567643404006958\n",
      "acc: 0.58\n",
      "loss: 2.4620862007141113\n",
      "acc: 0.61\n",
      "loss: 2.3582358360290527\n",
      "acc: 0.65\n",
      "loss: 2.257016181945801\n",
      "acc: 0.67\n",
      "loss: 2.1578075885772705\n",
      "acc: 0.67\n",
      "loss: 2.0614802837371826\n",
      "acc: 0.69\n",
      "loss: 1.967215895652771\n",
      "acc: 0.73\n",
      "loss: 1.8753242492675781\n",
      "acc: 0.75\n",
      "loss: 1.78602135181427\n",
      "acc: 0.78\n",
      "loss: 1.6997445821762085\n",
      "acc: 0.8\n",
      "loss: 1.6162673234939575\n",
      "acc: 0.8\n",
      "loss: 1.535270094871521\n",
      "acc: 0.81\n",
      "loss: 1.45712149143219\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "datamaker=train_based_self_detection(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    no_weight=True\n",
    ")\n",
    "\n",
    "input_data,output_label,label,highest_loss,lowest_loss= datamaker.make_data_pid(\n",
    "        total_number=100,\n",
    "        batch_size=100,\n",
    "        learning_rate=1,\n",
    "        warm_lr=1e-3,\n",
    "        channel=3,\n",
    "        dim1=224,\n",
    "        dim2=224,\n",
    "        output_size=1000,\n",
    "        randn_magnification=100,\n",
    "        confidence=1000000,\n",
    "        target_acc=0.8\n",
    "\n",
    ")\n",
    "print (input_data.dtype)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化搜索器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "max_latency 47.05151131607843\n",
      "min_latency 9.314525710054902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 45.31it/s]\n",
      "7it [00:00, 20.56it/s]\n",
      "7it [00:00, 29.21it/s]\n",
      "9it [00:00, 19.89it/s]\n",
      "7it [00:00, 24.77it/s]\n",
      "7it [00:00, 27.69it/s]\n",
      "7it [00:00, 27.69it/s]]\n",
      "9it [00:00, 13.43it/s]]\n",
      "7it [00:00, 22.73it/s]]\n",
      "7it [00:00, 22.23it/s]]\n",
      "7it [00:00, 22.20it/s]]\n",
      "7it [00:00, 22.67it/s]]\n",
      "7it [00:00, 22.30it/s]]\n",
      "9it [00:01,  7.00it/s]]\n",
      "7it [00:00,  9.98it/s]]\n",
      "7it [00:00,  9.97it/s]]\n",
      "20it [00:07,  1.51it/s]/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "23it [00:07,  2.95it/s]\n",
      "23it [00:00, 116.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD_finished\n",
      "Loss上限: 7.001727104187012\n",
      "acc上限: 0.0\n",
      "最长耗时: 49.80096864978824\n",
      "最短耗时: 25.97664598312157\n",
      "[0.83, 0.83, 0.83, 0.83, 0.83, 0.84, 0.84, 0.84, 0.84, 0.85, 0.7, 0.7, 0.71, 0.72, 0.8, 0.81, 0.81, 0.85, 0.84, 0.85, 0.84, 0.84, 0.84, 0.85, 0.85, 0.84, 0.84, 0.32, 0.32, 0.34, 0.41, 0.43, 0.43, 0.55, 0.55, 0.55, 0.74, 0.74, 0.74, 0.84, 0.84, 0.84, 0.86, 0.86, 0.86, 0.86, 0.86, 0.86]\n",
      "[8.02816, 8.02816, 8.02816, 8.02816, 8.02816, 8.02816, 8.02816, 8.02816, 8.02816, 8.02816, 4.01408, 4.01408, 4.01408, 4.01408, 4.01408, 4.01408, 4.01408, 4.01408, 4.01408, 4.01408, 4.01408, 4.01408, 4.01408, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 2.00704, 1.00352, 1.00352, 1.00352, 1.00352, 1.00352, 1.00352]\n"
     ]
    }
   ],
   "source": [
    "cut_step=0.2\n",
    "searcher=detection.Spliter.Recrusively_reduce_search(\n",
    "        model=model,\n",
    "        no_weight=True,\n",
    "        input_data=input_data,\n",
    "        output_label=output_label,\n",
    "        label=label,\n",
    "        device=device,\n",
    "        back_device=back_device,\n",
    "        highest_loss=highest_loss,\n",
    "        lowest_loss=lowest_loss,\n",
    "        # local_speed=2.72e10,   #Flops/s\n",
    "        local_speed=9.6e9,   #Flops/s\n",
    "        cloud_speed=1.7e13,    #Flops/s\n",
    "        network_speed=1e7,     #B/s\n",
    "        acc_cut_point=0.7,\n",
    "        # q=q,\n",
    ")\n",
    "searcher.init(cut_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.input_data.shape\n",
    "upper_bound=searcher.GA_init(50,step=cut_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找最优分割点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_num=min(upper_bound)\n",
    "quantized_network_list=[]\n",
    "quantized_acc_list=[]\n",
    "for i in range(2,50):\n",
    "    model_r,edge_layer_map=searcher.model_reduce([0]*i)\n",
    "    eA,c,eB=searcher.split(model_r,len(edge_layer_map))\n",
    "    qm=quantiseze_model([eA,c,eB])\n",
    "    quantized_network_list.append(searcher.network_evaluate_quantisized(qm))\n",
    "    acc,loss=searcher.acc_loss_evaluate(qm)\n",
    "    quantized_acc_list.append(acc)\n",
    "    # input()\n",
    "    torch.cuda.empty_cache()\n",
    "print(quantized_acc_list)\n",
    "print(quantized_network_list)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
