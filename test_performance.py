#!/usr/bin/env python3
"""
æµ‹è¯•æ€§èƒ½ç›‘æ§åŠŸèƒ½çš„ç®€å•è„šæœ¬
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from gptJtestsvd import PerformanceMonitor
import time
import torch

def test_performance_monitor():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨çš„åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨...")
    
    monitor = PerformanceMonitor()
    
    # å¼€å§‹å†…å­˜è·Ÿè¸ª
    monitor.start_memory_tracking()
    monitor.record_memory_snapshot("æµ‹è¯•å¼€å§‹")
    
    # æ¨¡æ‹Ÿä¸€äº›æ“ä½œ
    for i in range(5):
        # æ¨¡æ‹ŸGPUæ“ä½œ
        start_time = time.time()
        time.sleep(0.01)  # æ¨¡æ‹Ÿ10msçš„GPUæ“ä½œ
        gpu_time = time.time() - start_time
        monitor.record_cloud_time(gpu_time)
        
        # æ¨¡æ‹ŸCPUæ“ä½œ
        start_time = time.time()
        time.sleep(0.02)  # æ¨¡æ‹Ÿ20msçš„CPUæ“ä½œ
        cpu_time = time.time() - start_time
        monitor.record_edge_time(cpu_time)
        
        # æ¨¡æ‹Ÿç½‘ç»œä¼ è¾“
        monitor.record_network_time(0.005)  # 5msç½‘ç»œå»¶è¿Ÿ
        
        # å¢åŠ è®¡æ•°å™¨
        monitor.increment_token_count()
        monitor.increment_counters()
        
        monitor.record_memory_snapshot(f"è¿­ä»£ {i+1}")
    
    # åœæ­¢å†…å­˜è·Ÿè¸ª
    monitor.stop_memory_tracking()
    
    # æ‰“å°æŠ¥å‘Š
    monitor.print_detailed_report()
    monitor.print_memory_timeline()
    
    # è·å–æ‘˜è¦ç»Ÿè®¡
    stats = monitor.get_summary_stats()
    print(f"\nğŸ“Š æµ‹è¯•æ‘˜è¦:")
    print(f"   Tokenæ•°: {stats['token_count']}")
    print(f"   GPUæ€»æ—¶é—´: {stats['cloud_total_time']:.4f}s")
    print(f"   CPUæ€»æ—¶é—´: {stats['edge_total_time']:.4f}s")
    print(f"   ç½‘ç»œæ€»æ—¶é—´: {stats['network_total_time']:.4f}s")
    
    print("âœ… æ€§èƒ½ç›‘æ§å™¨æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_performance_monitor()
