{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACC 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.0\n",
      "loss: 8.103368759155273\n",
      "acc: 0.0\n",
      "loss: 7.964218616485596\n",
      "acc: 0.01\n",
      "loss: 7.7700371742248535\n",
      "acc: 0.02\n",
      "loss: 7.590518474578857\n",
      "acc: 0.02\n",
      "loss: 7.422794818878174\n",
      "acc: 0.02\n",
      "loss: 7.264231204986572\n",
      "acc: 0.02\n",
      "loss: 7.112494945526123\n",
      "acc: 0.02\n",
      "loss: 6.966763973236084\n",
      "acc: 0.02\n",
      "loss: 6.825649738311768\n",
      "acc: 0.02\n",
      "loss: 6.68864107131958\n",
      "acc: 0.02\n",
      "loss: 6.554722785949707\n",
      "acc: 0.03\n",
      "loss: 6.423401832580566\n",
      "acc: 0.03\n",
      "loss: 6.294726371765137\n",
      "acc: 0.05\n",
      "loss: 6.16775369644165\n",
      "acc: 0.05\n",
      "loss: 6.0415215492248535\n",
      "acc: 0.06\n",
      "loss: 5.916672229766846\n",
      "acc: 0.06\n",
      "loss: 5.792505264282227\n",
      "acc: 0.06\n",
      "loss: 5.668271541595459\n",
      "acc: 0.09\n",
      "loss: 5.544165134429932\n",
      "acc: 0.11\n",
      "loss: 5.419317722320557\n",
      "acc: 0.11\n",
      "loss: 5.294896602630615\n",
      "acc: 0.12\n",
      "loss: 5.170353889465332\n",
      "acc: 0.15\n",
      "loss: 5.04536771774292\n",
      "acc: 0.18\n",
      "loss: 4.920173645019531\n",
      "acc: 0.18\n",
      "loss: 4.794734001159668\n",
      "acc: 0.19\n",
      "loss: 4.6686692237854\n",
      "acc: 0.21\n",
      "loss: 4.542990207672119\n",
      "acc: 0.22\n",
      "loss: 4.417228698730469\n",
      "acc: 0.23\n",
      "loss: 4.291312217712402\n",
      "acc: 0.24\n",
      "loss: 4.165346145629883\n",
      "acc: 0.25\n",
      "loss: 4.040096282958984\n",
      "acc: 0.26\n",
      "loss: 3.9156510829925537\n",
      "acc: 0.27\n",
      "loss: 3.79168963432312\n",
      "acc: 0.32\n",
      "loss: 3.668851137161255\n",
      "acc: 0.33\n",
      "loss: 3.5475475788116455\n",
      "acc: 0.35\n",
      "loss: 3.428358793258667\n",
      "acc: 0.37\n",
      "loss: 3.310791015625\n",
      "acc: 0.41\n",
      "loss: 3.1947124004364014\n",
      "acc: 0.43\n",
      "loss: 3.080256938934326\n",
      "acc: 0.46\n",
      "loss: 2.96769642829895\n",
      "acc: 0.46\n",
      "loss: 2.8561809062957764\n",
      "acc: 0.5\n",
      "loss: 2.7466039657592773\n",
      "acc: 0.52\n",
      "loss: 2.6386513710021973\n",
      "acc: 0.55\n",
      "loss: 2.532841920852661\n",
      "acc: 0.58\n",
      "loss: 2.4288582801818848\n",
      "acc: 0.61\n",
      "loss: 2.3265061378479004\n",
      "acc: 0.61\n",
      "loss: 2.226597309112549\n",
      "acc: 0.62\n",
      "loss: 2.1286354064941406\n",
      "acc: 0.63\n",
      "loss: 2.0325093269348145\n",
      "acc: 0.66\n",
      "loss: 1.9385316371917725\n",
      "acc: 0.68\n",
      "loss: 1.8471990823745728\n",
      "acc: 0.7\n",
      "loss: 1.7583831548690796\n",
      "acc: 0.73\n",
      "loss: 1.6723949909210205\n",
      "acc: 0.77\n",
      "loss: 1.5890742540359497\n",
      "acc: 0.79\n",
      "loss: 1.5088027715682983\n",
      "acc: 0.81\n",
      "loss: 1.4314199686050415\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "max_latency 47.05151131607843\n",
      "min_latency 9.314525710054902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 40.71it/s]\n",
      "7it [00:00, 24.63it/s]\n",
      "7it [00:00, 24.85it/s]\n",
      "9it [00:00, 23.36it/s]\n",
      "7it [00:00, 34.59it/s]\n",
      "7it [00:00, 31.68it/s]\n",
      "7it [00:00, 33.19it/s]]\n",
      "9it [00:00, 10.83it/s]]\n",
      "7it [00:00, 19.59it/s]]\n",
      "7it [00:00, 20.35it/s]]\n",
      "7it [00:00, 19.80it/s]]\n",
      "7it [00:00, 19.60it/s]]\n",
      "7it [00:00, 19.78it/s]]\n",
      "9it [00:01,  6.38it/s]]\n",
      "7it [00:00,  8.70it/s]]\n",
      "7it [00:00,  8.76it/s]]\n",
      "20it [00:07,  1.34it/s]/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "23it [00:08,  2.76it/s]\n",
      "23it [00:00, 116.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD_finished\n",
      "0.83 1.3566932678222656\n",
      "___________________\n",
      "0.01 5.909055233001709\n",
      "___________________\n",
      "0.78 1.5236725807189941\n",
      "___________________\n",
      "0.71 1.8466787338256836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________\n",
      "0.42 3.3177361488342285\n"
     ]
    }
   ],
   "source": [
    "from detection.DataGenerator import train_based_self_detection\n",
    "import torch\n",
    "from detection.Loader.ResNet50Loader import Resnet50Loader\n",
    "from detection.Spliter import Recrusively_reduce_search \n",
    "model=Resnet50Loader()\n",
    "model=model.load()\n",
    "device='cuda:3'\n",
    "maker=train_based_self_detection(\n",
    "    device=device,\n",
    "    model=model,\n",
    "    no_weight=True\n",
    ")\n",
    "\n",
    "input_data,output_label,label,highest_loss,lowest_loss= maker.make_data_pid(\n",
    "        total_number=100,\n",
    "        batch_size=100,\n",
    "        learning_rate=1,\n",
    "        warm_lr=1e-3,\n",
    "        channel=3,\n",
    "        dim1=224,\n",
    "        dim2=224,\n",
    "        output_size=1000,\n",
    "        randn_magnification=100,\n",
    "        confidence=1000000,\n",
    "        target_acc=0.8\n",
    "\n",
    "    )\n",
    "input_data=input_data.detach()\n",
    "output_label=output_label.detach()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "searcher=Recrusively_reduce_search(\n",
    "        model=model,\n",
    "        no_weight=True,\n",
    "        input_data=input_data,\n",
    "        output_label=output_label,\n",
    "        label=label,\n",
    "        device=device,\n",
    "        highest_loss=highest_loss,\n",
    "        lowest_loss=lowest_loss,\n",
    "        # local_speed=2.72e10,   #Flops/s\n",
    "        local_speed=9.6e9,   #Flops/s\n",
    "        cloud_speed=1.7e13,    #Flops/s\n",
    "        network_speed=1e7,     #B/s\n",
    "        acc_cut_point=0.7,\n",
    "        # q=q,\n",
    ")\n",
    "\n",
    "searcher.init(0.2)\n",
    "acc,loss=searcher.acc_loss_evaluate(model)\n",
    "print(acc,loss)\n",
    "model1,_=searcher.model_reduce([3])\n",
    "acc,loss=searcher.acc_loss_evaluate(model1)\n",
    "print(\"___________________\")\n",
    "print(acc,loss)\n",
    "model2,_=searcher.model_reduce([0,3])\n",
    "acc,loss=searcher.acc_loss_evaluate(model2)\n",
    "print(\"___________________\")\n",
    "print(acc,loss)\n",
    "model3,_=searcher.model_reduce([0,0,3])\n",
    "acc,loss=searcher.acc_loss_evaluate(model3)\n",
    "print(\"___________________\")\n",
    "print(acc,loss)\n",
    "model4,_=searcher.model_reduce([0,0,3,3])\n",
    "acc,loss=searcher.acc_loss_evaluate(model4)\n",
    "print(\"___________________\")\n",
    "print(acc,loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE:loading_resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE:loading_finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.0\n",
      "loss: 8.192535400390625\n",
      "acc: 0.0\n",
      "loss: 8.057259559631348\n",
      "acc: 0.0\n",
      "loss: 7.868487358093262\n",
      "acc: 0.0\n",
      "loss: 7.692719459533691\n",
      "acc: 0.01\n",
      "loss: 7.527642726898193\n",
      "acc: 0.01\n",
      "loss: 7.371318340301514\n",
      "acc: 0.01\n",
      "loss: 7.222101211547852\n",
      "acc: 0.01\n",
      "loss: 7.079283237457275\n",
      "acc: 0.01\n",
      "loss: 6.940860271453857\n",
      "acc: 0.01\n",
      "loss: 6.806171894073486\n",
      "acc: 0.01\n",
      "loss: 6.674800872802734\n",
      "acc: 0.02\n",
      "loss: 6.545608997344971\n",
      "acc: 0.02\n",
      "loss: 6.417995929718018\n",
      "acc: 0.03\n",
      "loss: 6.291906833648682\n",
      "acc: 0.03\n",
      "loss: 6.166782855987549\n",
      "acc: 0.04\n",
      "loss: 6.042614459991455\n",
      "acc: 0.04\n",
      "loss: 5.918995380401611\n",
      "acc: 0.04\n",
      "loss: 5.795289039611816\n",
      "acc: 0.04\n",
      "loss: 5.6719255447387695\n",
      "acc: 0.05\n",
      "loss: 5.54874849319458\n",
      "acc: 0.07\n",
      "loss: 5.425347805023193\n",
      "acc: 0.08\n",
      "loss: 5.301200866699219\n",
      "acc: 0.1\n",
      "loss: 5.176677227020264\n",
      "acc: 0.11\n",
      "loss: 5.052516460418701\n",
      "acc: 0.13\n",
      "loss: 4.927635192871094\n",
      "acc: 0.16\n",
      "loss: 4.802219390869141\n",
      "acc: 0.17\n",
      "loss: 4.6773810386657715\n",
      "acc: 0.17\n",
      "loss: 4.552337646484375\n",
      "acc: 0.17\n",
      "loss: 4.427135467529297\n",
      "acc: 0.2\n",
      "loss: 4.302361965179443\n",
      "acc: 0.2\n",
      "loss: 4.178050518035889\n",
      "acc: 0.21\n",
      "loss: 4.054171085357666\n",
      "acc: 0.26\n",
      "loss: 3.930820941925049\n",
      "acc: 0.3\n",
      "loss: 3.8087894916534424\n",
      "acc: 0.34\n",
      "loss: 3.687905788421631\n",
      "acc: 0.36\n",
      "loss: 3.568035125732422\n",
      "acc: 0.37\n",
      "loss: 3.4493894577026367\n",
      "acc: 0.38\n",
      "loss: 3.3318986892700195\n",
      "acc: 0.4\n",
      "loss: 3.2152962684631348\n",
      "acc: 0.41\n",
      "loss: 3.0997209548950195\n",
      "acc: 0.46\n",
      "loss: 2.9857254028320312\n",
      "acc: 0.46\n",
      "loss: 2.873063564300537\n",
      "acc: 0.49\n",
      "loss: 2.76198673248291\n",
      "acc: 0.5\n",
      "loss: 2.6529159545898438\n",
      "acc: 0.54\n",
      "loss: 2.545565366744995\n",
      "acc: 0.57\n",
      "loss: 2.439539670944214\n",
      "acc: 0.59\n",
      "loss: 2.335402250289917\n",
      "acc: 0.62\n",
      "loss: 2.232801675796509\n",
      "acc: 0.62\n",
      "loss: 2.1320717334747314\n",
      "acc: 0.64\n",
      "loss: 2.034125328063965\n",
      "acc: 0.66\n",
      "loss: 1.9382262229919434\n",
      "acc: 0.67\n",
      "loss: 1.8449556827545166\n",
      "acc: 0.71\n",
      "loss: 1.754036545753479\n",
      "acc: 0.73\n",
      "loss: 1.6655999422073364\n",
      "acc: 0.77\n",
      "loss: 1.5794693231582642\n",
      "acc: 0.79\n",
      "loss: 1.4957338571548462\n",
      "acc: 0.82\n",
      "loss: 1.414328932762146\n"
     ]
    }
   ],
   "source": [
    "from detection.DataGenerator import train_based_self_detection\n",
    "from detection.Loader.ResNet50Loader import Resnet50Loader\n",
    "import detection.Spliter\n",
    "import torch\n",
    "print(\"CODE:loading_resnet50\")\n",
    "model=Resnet50Loader().load()\n",
    "print(\"CODE:loading_finished\")\n",
    "device='cuda:1'\n",
    "datamaker=train_based_self_detection(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    no_weight=True\n",
    ")\n",
    "\n",
    "input_data,output_label,label,highest_loss,lowest_loss= datamaker.make_data_pid(\n",
    "        total_number=100,\n",
    "        batch_size=100,\n",
    "        learning_rate=1,\n",
    "        warm_lr=1e-3,\n",
    "        channel=3,\n",
    "        dim1=224,\n",
    "        dim2=224,\n",
    "        output_size=1000,\n",
    "        randn_magnification=100,\n",
    "        confidence=1000000,\n",
    "        target_acc=0.8\n",
    "\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "max_latency 47.05151131607843\n",
      "min_latency 9.314525710054902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 34.31it/s]\n",
      "7it [00:00, 35.32it/s]\n",
      "7it [00:00, 20.99it/s]\n",
      "9it [00:00, 18.53it/s]\n",
      "7it [00:00, 29.25it/s]\n",
      "7it [00:00, 29.47it/s]\n",
      "7it [00:00, 31.92it/s]]\n",
      "9it [00:00, 17.12it/s]]\n",
      "7it [00:00, 22.74it/s]]\n",
      "7it [00:00, 22.65it/s]]\n",
      "7it [00:00, 22.83it/s]]\n",
      "7it [00:00, 15.77it/s]]\n",
      "7it [00:00, 22.76it/s]]\n",
      "9it [00:01,  7.05it/s]]\n",
      "7it [00:00, 10.00it/s]]\n",
      "7it [00:00, 10.08it/s]]\n",
      "20it [00:07,  1.50it/s]/home/tianruiming/miniconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "23it [00:08,  2.72it/s]\n",
      "23it [00:00, 117.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD_finished\n",
      "Splited_Model(\n",
      "  (model_list): ModuleList(\n",
      "    (0): SVDED_Conv(\n",
      "      (conv_layer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (newlinear1): Linear(in_features=147, out_features=64, bias=False)\n",
      "      (newlinear2): Linear(in_features=64, out_features=64, bias=False)\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): MyBot(\n",
      "      (conv1): SVDED_Conv(\n",
      "        (conv_layer): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (newlinear1): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (newlinear2): Linear(in_features=64, out_features=64, bias=False)\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): SVDED_Conv(\n",
      "        (conv_layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (newlinear1): Linear(in_features=576, out_features=64, bias=False)\n",
      "        (newlinear2): Linear(in_features=64, out_features=64, bias=False)\n",
      "      )\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): SVDED_Conv(\n",
      "        (conv_layer): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (newlinear1): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (newlinear2): Linear(in_features=64, out_features=256, bias=False)\n",
      "      )\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-----------------\n",
      "Splited_Model(\n",
      "  (model_list): ModuleList(\n",
      "    (0-1): 2 x MyBot(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): MyBot(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3-5): 3 x MyBot(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): MyBot(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (7-11): 5 x MyBot(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (12): MyBot(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (13-14): 2 x MyBot(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (15): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (16): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n",
      "-----------------\n",
      "Splited_Model(\n",
      "  (model_list): ModuleList(\n",
      "    (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "-----------------\n",
      "Splited_Model(\n",
      "  (model_list): ModuleList(\n",
      "    (0): SVDED_Conv(\n",
      "      (conv_layer): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (newlinear1): Linear(in_features=147, out_features=64, bias=False)\n",
      "      (newlinear2): Linear(in_features=64, out_features=64, bias=False)\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): MyBot(\n",
      "      (conv1): SVDED_Conv(\n",
      "        (conv_layer): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (newlinear1): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (newlinear2): Linear(in_features=64, out_features=64, bias=False)\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): SVDED_Conv(\n",
      "        (conv_layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (newlinear1): Linear(in_features=576, out_features=64, bias=False)\n",
      "        (newlinear2): Linear(in_features=64, out_features=64, bias=False)\n",
      "      )\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): SVDED_Conv(\n",
      "        (conv_layer): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (newlinear1): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (newlinear2): Linear(in_features=64, out_features=256, bias=False)\n",
      "      )\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-----------------\n",
      "Splited_Model(\n",
      "  (model_list): ModuleList(\n",
      "    (0-1): 2 x MyBot(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): MyBot(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3-5): 3 x MyBot(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): MyBot(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (7-11): 5 x MyBot(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (12): MyBot(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (13-14): 2 x MyBot(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (15): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (16): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n",
      "-----------------\n",
      "Splited_Model(\n",
      "  (model_list): ModuleList(\n",
      "    (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "searcher=detection.Spliter.Recrusively_reduce_search(\n",
    "        model=model,\n",
    "        no_weight=True,\n",
    "        input_data=input_data,\n",
    "        output_label=output_label,\n",
    "        label=label,\n",
    "        device=device,\n",
    "        highest_loss=highest_loss,\n",
    "        lowest_loss=lowest_loss,\n",
    "        # local_speed=2.72e10,   #Flops/s\n",
    "        local_speed=9.6e9,   #Flops/s\n",
    "        cloud_speed=1.7e13,    #Flops/s\n",
    "        network_speed=1e7,     #B/s\n",
    "        acc_cut_point=0.7,\n",
    "        # q=q,\n",
    ")\n",
    "searcher.init(0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,edge_layer_map=searcher.model_reduce([0,0,0,0])\n",
    "eA,c,eB=searcher.split(model,len(edge_layer_map))\n",
    "\n",
    "print(eA)\n",
    "print('-----------------')\n",
    "print(c)\n",
    "print('-----------------')\n",
    "print(eB)\n",
    "print('-----------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
